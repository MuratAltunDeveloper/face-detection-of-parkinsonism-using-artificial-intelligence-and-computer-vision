{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMzimdkyWHhx/vQcfumlML9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"id":"ZdcmXvKuPqWj","executionInfo":{"status":"ok","timestamp":1733724641604,"user_tz":-180,"elapsed":387,"user":{"displayName":"asistlab","userId":"04370448145332600114"}}},"outputs":[],"source":[]},{"cell_type":"markdown","source":["## 1-videodan her bir çerçeveye (frame) ait özellik vektörleri çıkarıyorum ve bu vektörlerin ortalaması alınarak tek bir özellik vektörü elde ediliyorum.bu vektörü vektör boyutunu indirgeme yöntemi  ile minimalize ediyorum"],"metadata":{"id":"0Hv_K9LeT-Im"}},{"cell_type":"markdown","source":["drive bağlanma"],"metadata":{"id":"5MQ7ndF3BspP"}},{"cell_type":"code","source":["from google.colab import drive  # google.colab modülünü içe aktarın\n","drive.mount('/content/drive')  # Google Drive'ı bağlayın\n","import os"],"metadata":{"id":"yzlwSqdwP2-f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733724643942,"user_tz":-180,"elapsed":1957,"user":{"displayName":"asistlab","userId":"04370448145332600114"}},"outputId":"4b322c04-2999-4131-aab6-e1c0c7baf88c"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["library"],"metadata":{"id":"zX6iah7KBxD8"}},{"cell_type":"code","source":["import torch\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","import cv2\n","import numpy as np\n","from PIL import Image\n","from torchvision import models"],"metadata":{"id":"dCHEvn0OP3BK","executionInfo":{"status":"ok","timestamp":1733724643942,"user_tz":-180,"elapsed":4,"user":{"displayName":"asistlab","userId":"04370448145332600114"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["preprocess  and model"],"metadata":{"id":"zSKRf7c4B4Cx"}},{"cell_type":"code","source":["# Görüntü ön işleme dönüşümleri\n","preprocess = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","\n","\n","# Cihaz seçimi\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Fine-tuned ResNet50 modelini yükleme\n","model = models.resnet50(pretrained=False)\n","model.fc = nn.Linear(model.fc.in_features, 2)  # 2 sınıf için\n","model.load_state_dict(torch.load(\"/content/drive/My Drive/ASISTLAB_ARTIFICAL/tubitak_2209/CNN_BASED_YUZBILGI_EDINIM/parkinson_fine_tuned_resnet50.pth\", map_location=device))\n","\n","# Modeli değerlendirme moduna al\n","model.eval()"],"metadata":{"id":"WbVHGjNSP3Dy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733724649999,"user_tz":-180,"elapsed":6060,"user":{"displayName":"asistlab","userId":"04370448145332600114"}},"outputId":"b9231c17-22c0-42ab-ce00-1c1b7b442b87"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n","<ipython-input-6-9e5a1048fb21>:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(\"/content/drive/My Drive/ASISTLAB_ARTIFICAL/tubitak_2209/CNN_BASED_YUZBILGI_EDINIM/parkinson_fine_tuned_resnet50.pth\", map_location=device))\n"]},{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (4): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (5): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["Global ortalama havuzlama katmanını"],"metadata":{"id":"IkvvoZbZCCsF"}},{"cell_type":"code","source":["# Global ortalama havuzlama katmanını ekle\n","class ResNetFeatureExtractor(nn.Module):\n","    def __init__(self, original_model):\n","        super().__init__()\n","        # Modelin son sınıflandırma katmanı hariç tüm katmanlarını aldım\n","        self.features = nn.Sequential(*list(original_model.children())[:-1])\n","\n","    def forward(self, x):\n","        # Global ortalama havuzlama\n","        x = self.features(x)\n","        x = torch.mean(x, dim=[2, 3])  # Tüm konumlar üzerinden ortalama\n","        return x\n","\n","# Özellik çıkarıcıyı oluştur\n","feature_extractor = ResNetFeatureExtractor(model).to(device)\n","\n","\n","#!!girdiyi görüntüyü  resnet50 features ( Modelin son sınıflandırma katmanı hariç tüm katmanlarını alarak oluşturlmuş features) kısmından geçirdim ve (    x = torch.mean(x, dim=[2, 3])  )\n","# ile Global Ortalama Havuzlama bu özellik haritalarını özetler.\n","\n"],"metadata":{"id":"3KwwgkuXP3Gu","executionInfo":{"status":"ok","timestamp":1733724649999,"user_tz":-180,"elapsed":3,"user":{"displayName":"asistlab","userId":"04370448145332600114"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["\n","def extract_features_from_video(video_path):\n","    \"\"\"\n","    Videodan frame'ler üzerinden özellik vektörleri çıkarır\n","\n","    Args:\n","        video_path (str): Video dosyasının yolu\n","\n","    Returns:\n","        np.ndarray: Video için çıkarılmış özellik vektörü\n","    \"\"\"\n","    cap = cv2.VideoCapture(video_path)\n","    all_frame_features = []\n","\n","    while True:\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","\n","        # BGR'yi RGB'ye çevir\n","        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","        frame_pil = Image.fromarray(frame_rgb)\n","\n","        # Ön işleme\n","        input_tensor = preprocess(frame_pil).unsqueeze(0).to(device)\n","\n","        # Özellik çıkarma\n","        with torch.no_grad():\n","            frame_features = feature_extractor(input_tensor)\n","\n","        # NumPy dizisine çevir ve listeye ekle\n","        frame_features_np = frame_features.cpu().numpy().flatten()\n","        all_frame_features.append(frame_features_np)\n","\n","    cap.release()\n","\n","    # Tüm frame özelliklerinin ortalamasını al\n","    video_feature_vector = np.mean(all_frame_features, axis=0)\n","\n","    return video_feature_vector\n","\n","# Örnek kullanım\n","video_paths = [\n","    \"/content/drive/MyDrive/ASISTLAB_ARTIFICAL/tubitak_2209/dataset/healthy_head/canan-karaman-durus-tekayak-3-trim-merged-1_s9hUjGzM (1).mp4\"\n","]\n","\n","# Her video için özellik vektörlerini çıkar\n","video_features = [extract_features_from_video(path) for path in video_paths]"],"metadata":{"id":"4-czmXnHP3JK","executionInfo":{"status":"ok","timestamp":1733724752305,"user_tz":-180,"elapsed":102308,"user":{"displayName":"asistlab","userId":"04370448145332600114"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["for i, features in enumerate(video_features):\n","    print(f\"Video {i + 1} için  özellik vektörü:\\n\", features)\n","    print(f\"\\n{features.shape}\")\n"],"metadata":{"id":"cAU1yjCWP3Lv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733734341187,"user_tz":-180,"elapsed":406,"user":{"displayName":"asistlab","userId":"04370448145332600114"}},"outputId":"55ff88e1-15c5-43f2-f9ee-28edf0256203"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Video 1 için  özellik vektörü:\n"," [0.42138568 1.2688149  0.5372501  ... 0.0079769  0.6910317  0.09482634]\n","\n","(2048,)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Kz2XQYzfnQ0o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1.1PCA (Principal Component Analysis)"],"metadata":{"id":"liUHWCACEc_p"}},{"cell_type":"code","source":["\n","from sklearn.decomposition import PCA\n","\n","\n","\n","# Hedef boyut (ör. 10)\n","target_size = 10\n","\n","# Parçalar halinde ortalama alarak boyut indirgeme\n","chunk_size = len(features) // target_size\n","reduced_features = [np.mean(features[i:i + chunk_size]) for i in range(0, len(features), chunk_size)]\n","\n","# Hedef boyutun tam bölünememesi durumunda ek düzenleme\n","reduced_features = reduced_features[:target_size]\n","\n","print(\"Boyut indirgenmiş özellik vektörü:\", reduced_features)"],"metadata":{"id":"UBpOucbaP3OC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733725253272,"user_tz":-180,"elapsed":508,"user":{"displayName":"asistlab","userId":"04370448145332600114"}},"outputId":"afc32500-9473-4351-9f27-75369a1a0067"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Boyut indirgenmiş özellik vektörü: [0.49169412, 0.4929406, 0.51587707, 0.45886022, 0.50990295, 0.483696, 0.50861365, 0.5016021, 0.4826135, 0.4557583]\n"]}]},{"cell_type":"markdown","source":["1.2 t-SNE (t-Distributed Stochastic Neighbor Embedding)"],"metadata":{"id":"9PnTASbyZNSH"}},{"cell_type":"code","source":["#   VERİM  1D BU YÜZDEN TERCİH ETMEDİM ."],"metadata":{"id":"UPVJdRh8P3Qi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733731825166,"user_tz":-180,"elapsed":402,"user":{"displayName":"asistlab","userId":"04370448145332600114"}},"outputId":"5a10e5ca-5644-4056-d039-243727aedb1a"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Boyut indirgenmiş özellik vektörü: [[106.925316  -80.628944 ]\n"," [-81.91029    89.11271  ]\n"," [ 14.721625   96.54583  ]\n"," [ 46.499283   17.33064  ]\n"," [-52.674313   -5.4060664]]\n"]}]},{"cell_type":"markdown","source":["1.3 (Deep Feature Extraction)  == RNN VEYA TRANSFORMER,sıralı ve sekans veri tipi için benim video datasetim olur"],"metadata":{"id":"PuJ7WlAPePaO"}},{"cell_type":"code","source":["\n","# 1D vektörleri PyTorch tensörlerine dönüştürüdüm ve RNN için uygun hale getirin\n","video_tensor = torch.tensor(video_features, dtype=torch.float32).unsqueeze(0)\n","# RNN modelini tanımlayalım\n","class RNN_Dim_Reduction(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size):\n","        super(RNN_Dim_Reduction, self).__init__()\n","        self.rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, x):\n","        # RNN katmanı\n","        out, _ = self.rnn(x)\n","        # Son çıktıyı al ve lineer katman ile 10 boyutlu hale getir\n","        out = self.fc(out[:, -1, :])  # Sadece son RNN çıktısını alıyoruz\n","        return out\n","\n","# RNN modelini başlatıyoruz\n","input_size = 2048  # Her kare için 100 elemanlı özellik vektörü\n","hidden_size = 64  # RNN hücre sayısı\n","output_size = 10  # İndirgenmiş boyut (10 elemanlı özellik vektörü)\n","\n","model = RNN_Dim_Reduction(input_size, hidden_size, output_size)\n","\n","# Modeli çalıştırıyoruz\n","output = model(video_tensor)\n","\n","# Çıktıyı yazdıralım\n","print(\"Boyut indirgenmiş vektör:\", output)"],"metadata":{"id":"N-tmUa_uP3TC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733734416202,"user_tz":-180,"elapsed":923,"user":{"displayName":"asistlab","userId":"04370448145332600114"}},"outputId":"7df20e6b-c60d-4f31-cd67-4ec8a543d888"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Boyut indirgenmiş vektör: tensor([[ 0.4319,  0.0198,  0.1899, -0.6073, -0.1205, -0.2275, -0.2019, -0.6704,\n","         -0.1692, -0.5188]], grad_fn=<AddmmBackward0>)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"oIUXhg5RP3Vn","executionInfo":{"status":"ok","timestamp":1733724752306,"user_tz":-180,"elapsed":5,"user":{"displayName":"asistlab","userId":"04370448145332600114"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["## 2-videodan çıkarılan feature maplerin sayısallaştırılması ve bu sayısallaştırılmış vektörlerden ajanlar sayesinde (SVM FEATURE EVALUATOR,GAİN RATİO EVALUATOR,INFO GAİN EVALUATOR,CORRELATİON FEATURE SELECTİON) SAYISAL özelliklerin elde edilmesi"],"metadata":{"id":"Xy6cdgvaovPs"}},{"cell_type":"code","source":[],"metadata":{"id":"wDlju8DWP3YG","executionInfo":{"status":"ok","timestamp":1733724752306,"user_tz":-180,"elapsed":5,"user":{"displayName":"asistlab","userId":"04370448145332600114"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"_AlOs1cnpBaN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"YeLRo5qrpBdF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"cxphtFZdpBft"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"1JdZphr7pBih"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"W3S1dbmqpBlD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ftImuqdOP3az","executionInfo":{"status":"ok","timestamp":1733724752306,"user_tz":-180,"elapsed":5,"user":{"displayName":"asistlab","userId":"04370448145332600114"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Fum5401hP3di","executionInfo":{"status":"ok","timestamp":1733724752306,"user_tz":-180,"elapsed":5,"user":{"displayName":"asistlab","userId":"04370448145332600114"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qEDd5X9BP3f2","executionInfo":{"status":"ok","timestamp":1733724752306,"user_tz":-180,"elapsed":4,"user":{"displayName":"asistlab","userId":"04370448145332600114"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"yrvlp59DP3iK","executionInfo":{"status":"ok","timestamp":1733724752306,"user_tz":-180,"elapsed":4,"user":{"displayName":"asistlab","userId":"04370448145332600114"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"SzU6GCAiP3km","executionInfo":{"status":"ok","timestamp":1733724752306,"user_tz":-180,"elapsed":4,"user":{"displayName":"asistlab","userId":"04370448145332600114"}}},"execution_count":8,"outputs":[]}]}